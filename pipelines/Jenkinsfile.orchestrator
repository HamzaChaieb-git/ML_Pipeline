pipeline {
    agent any
    
    environment {
        BASE_IMAGE = 'hamzachaieb01/dockerfinal'
        TAG = 'latest'
        WORKSPACE_SAFE = sh(script: 'echo "${WORKSPACE}" | sed "s/ /\\ /g"', returnStdout: true).trim()
        MLFLOW_TRACKING_URI = 'http://localhost:5001'
        MLFLOW_EXPERIMENT_NAME = 'churn_prediction'
    }
    
    options {
        timeout(time: 2, unit: 'HOURS')
        disableConcurrentBuilds()
    }
    
    stages {
        stage('Docker Login') {
            steps {
                withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                                usernameVariable: 'DOCKER_USERNAME', 
                                passwordVariable: 'DOCKER_PASSWORD')]) {
                    sh 'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin'
                }
            }
        }
        
        stage('Pull Image') {
            steps {
                script {
                    sh "docker pull ${BASE_IMAGE}:${TAG}"
                }
            }
        }
        
        stage('Setup MLflow') {
            steps {
                script {
                    sh '''
                        docker rm -f mlflow_server model_trainer || true
                        docker network rm mlflow_net || true
                        rm -rf ${WORKSPACE}/mlflow_data || true
                        
                        docker network create mlflow_net || true
                        
                        mkdir -p "${WORKSPACE_SAFE}/mlflow_data"/{database,artifacts}
                        chmod -R 777 "${WORKSPACE_SAFE}/mlflow_data"
                        
                        docker run -d \
                            --name mlflow_server \
                            --network mlflow_net \
                            -p 5001:5001 \
                            -v "${WORKSPACE_SAFE}/mlflow_data/database":/mlflow_data/database \
                            -v "${WORKSPACE_SAFE}/mlflow_data/artifacts":/mlflow_data/artifacts \
                            ${BASE_IMAGE}:${TAG} \
                            bash -c "
                                mkdir -p /mlflow_data/database /mlflow_data/artifacts && \
                                chmod -R 777 /mlflow_data && \
                                mlflow server \
                                    --backend-store-uri sqlite:///mlflow_data/database/mlflow.db \
                                    --default-artifact-root /mlflow_data/artifacts \
                                    --host 0.0.0.0 \
                                    --port 5001 \
                                    --workers 1
                            "
                        sleep 15
                    '''
                }
            }
        }
        
        stage('Code Quality Checks') {
            steps {
                script {
                    try {
                        // Create workspace for reports
                        sh 'mkdir -p quality_reports'

                        // Run Flake8
                        sh '''
                            docker run --name flake8_check -w /app ${BASE_IMAGE}:${TAG} \
                                flake8 --output-file=flake8_report.txt . || true
                            docker cp flake8_check:/app/flake8_report.txt quality_reports/ || true
                            docker rm -f flake8_check || true
                        '''

                        // Run Black
                        sh '''
                            docker run --name black_check -w /app ${BASE_IMAGE}:${TAG} \
                                black --check . > quality_reports/black_report.txt 2>&1 || true
                            docker rm -f black_check || true
                        '''

                        // Run Bandit
                        sh '''
                            docker run --name bandit_check -w /app ${BASE_IMAGE}:${TAG} \
                                bandit -r . -f txt -o bandit_report.txt || true
                            docker cp bandit_check:/app/bandit_report.txt quality_reports/ || true
                            docker rm -f bandit_check || true
                        '''

                        // Commit quality reports to image (optional)
                        sh '''
                            docker create --name quality_container ${BASE_IMAGE}:${TAG}
                            docker cp quality_reports/. quality_container:/app/quality_reports/ || true
                            docker commit quality_container ${BASE_IMAGE}:${TAG}-quality
                            docker push ${BASE_IMAGE}:${TAG}-quality
                            echo "Quality reports saved to image: ${BASE_IMAGE}:${TAG}-quality"
                        '''
                    } catch (Exception e) {
                        echo "Error during quality checks: ${e.message}"
                        currentBuild.result = 'UNSTABLE'
                    }
                }
            }
        }
        
        stage('Process Data and Train Model') {
            steps {
                script {
                    try {
                        sh """
                            docker run -d \
                                --name model_trainer \
                                --network mlflow_net \
                                -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                -e MLFLOW_EXPERIMENT_NAME=churn_prediction \
                                -v "${WORKSPACE_SAFE}/mlflow_data/database":/mlflow_data/database \
                                -v "${WORKSPACE_SAFE}/mlflow_data/artifacts":/mlflow_data/artifacts \
                                ${BASE_IMAGE}:${TAG} \
                                tail -f /dev/null
                            
                            # Ensure /app exists and has correct permissions
                            docker exec model_trainer bash -c "
                                mkdir -p /app && \
                                mkdir -p /app/mlruns && \
                                chmod -R 777 /app /mlflow_data && \
                                touch /app/test_file.txt && \
                                rm /app/test_file.txt
                            "
                            
                            # Process data
                            docker exec -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                model_trainer python -u -m main prepare_data > /app/data_output.txt 2>&1
                            
                            # Train model
                            docker exec -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                -e MLFLOW_EXPERIMENT_NAME=churn_prediction \
                                model_trainer python -u -m main train_model > /app/train_output.txt 2>&1
                            
                            sleep 10
                            
                            # Verify output files
                            if ! docker exec model_trainer test -f /app/train_output.txt; then
                                echo "ERROR: train_output.txt not found"
                                docker logs model_trainer > train_logs.txt 2>&1 || echo "Failed to save logs"
                                exit 1
                            fi
                            
                            # Get MLflow run ID
                            RUN_ID=\$(docker exec model_trainer grep 'MLflow run ID:' /app/train_output.txt | awk '{print \$NF}' || echo 'no_run_id')
                            echo "Training Run ID: \$RUN_ID"
                            
                            # Evaluate model
                            docker exec -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                -e MLFLOW_EXPERIMENT_NAME=churn_prediction \
                                model_trainer python -u -m main evaluate_model > /app/model_output.txt 2>&1
                            
                            # Save model
                            docker exec -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                model_trainer python -m main save_model
                            
                            # Commit and push updated image (optional)
                            docker commit model_trainer ${BASE_IMAGE}:${TAG}-final
                            docker push ${BASE_IMAGE}:${TAG}-final
                            
                            # Cleanup
                            docker rm -f model_trainer || true
                        """
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error "Pipeline failed: ${e.message}"
                    }
                }
            }
        }
        
        stage('Analyze Reports') {
            steps {
                script {
                    sh '''
                        echo "=== Flake8 Results ==="
                        cat quality_reports/flake8_report.txt || echo "No Flake8 issues found"

                        echo "\\n=== Black Results ==="
                        cat quality_reports/black_report.txt || echo "No Black issues found"

                        echo "\\n=== Bandit Results ==="
                        cat quality_reports/bandit_report.txt || echo "No Bandit issues found"
                    '''
                }
            }
        }
        
        stage('Evaluate Model') {
            steps {
                timeout(time: 2, unit: 'MINUTES') {
                    script {
                        sh '''
                            echo "=== Model Evaluation Results ==="
                            docker exec \
                                -e MLFLOW_TRACKING_URI=http://localhost:5001 \
                                model_trainer \
                                python -c "
import mlflow
from mlflow.tracking import MlflowClient

try:
    client = MlflowClient()
    experiment = client.get_experiment_by_name('${MLFLOW_EXPERIMENT_NAME}')
    
    if experiment:
        runs = client.search_runs(experiment_ids=[experiment.experiment_id])
        if runs:
            run = runs[0]
            print(f'\\nRun ID: {run.info.run_id}')
            print(f'Status: {run.info.status}')
            print('\\nMetrics:')
            for key, value in run.data.metrics.items():
                print(f'{key}: {value:.4f}')
        else:
            print('No runs found')
    else:
        print('Experiment not found')
except Exception as e:
    print(f'Error: {str(e)}')
"
                        '''
                    }
                }
            }
        }
    }
    
    post {
        always {
            sh '''
                docker rm -f model_trainer || true
                docker logout
                docker system prune -f
                rm -f data_output.txt train_output.txt model_output.txt train_logs.txt
            '''
            archiveArtifacts artifacts: 'quality_reports/**/*,data_output.txt,train_output.txt,model_output.txt,train_logs.txt', 
                           allowEmptyArchive: true,
                           fingerprint: true
            cleanWs()
        }
        success {
            echo "Pipeline completed successfully. Check MLflow at ${MLFLOW_TRACKING_URI}"
        }
        failure {
            echo "Pipeline failed"
        }
        unstable {
            echo "Pipeline completed with issues"
        }
    }
}
