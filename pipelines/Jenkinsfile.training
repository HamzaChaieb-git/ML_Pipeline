pipeline {
    agent any
    
    environment {
        BASE_IMAGE = 'hamzachaieb01/ml-pipeline'
        DATA_IMAGE = 'hamzachaieb01/ml-data'
        MODEL_IMAGE = 'hamzachaieb01/ml-model'
        TAG = 'latest'
        MLFLOW_TRACKING_URI = 'http://mlflow:5000'
        WORKSPACE_SAFE = sh(script: 'echo "${WORKSPACE}" | sed "s/ /\\ /g"', returnStdout: true).trim()
    }
    
    options {
        timeout(time: 1, unit: 'HOURS')
        disableConcurrentBuilds()
    }
    
    stages {
        stage('Docker Login') {
            steps {
                withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                               usernameVariable: 'DOCKER_USERNAME', 
                               passwordVariable: 'DOCKER_PASSWORD')]) {
                    sh 'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin'
                }
            }
        }
        
        stage('Pull Images') {
            steps {
                script {
                    sh """
                        docker pull ${BASE_IMAGE}:${TAG}
                        docker pull ${DATA_IMAGE}:${TAG}
                    """
                }
            }
        }
        
        stage('Train Model') {
            steps {
                script {
                    try {
                        sh """
                            # Create data container
                            docker create --name data_container ${DATA_IMAGE}:${TAG}
                            
                            # Create model trainer container and ensure /app directory exists
                            docker run -d --name model_trainer \
                                -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \
                                --volumes-from data_container \
                                ${BASE_IMAGE}:${TAG} \
                                tail -f /dev/null
                            
                            # Create /app directory if it doesn’t exist
                            docker exec model_trainer mkdir -p /app
                            
                            # Train model and capture output
                            docker exec model_trainer sh -c "python -u -m main train_model > /app/train_output.txt 2>&1"
                            
                            # Wait briefly to ensure output is written
                            sleep 5  # Increased from 2 to ensure file writing completes
                            
                            # Check if train_output.txt exists
                            if [ ! -f /app/train_output.txt ]; then
                                echo "ERROR: train_output.txt not found in /app/"
                                exit 1
                            fi
                            
                            # Get the run ID from training output, handle empty or missing line
                            RUN_ID=\$(grep 'MLflow run ID:' /app/train_output.txt | awk '{print \$NF}' || echo '')
                            if [ -z "\$RUN_ID" ]; then
                                echo "WARNING: Could not find MLflow run ID in train_output.txt. Checking MLflow logs..."
                                RUN_ID=\$(docker exec model_trainer python3 -c '
import mlflow
client = mlflow.MlflowClient("${MLFLOW_TRACKING_URI}")
runs = client.search_runs(experiment_ids=["0"])  # Use search_runs instead of list_run_infos
print(runs[0].info.run_id if runs else "")
' || echo '')
                                if [ -z "\$RUN_ID" ]; then
                                    echo "ERROR: Failed to retrieve MLflow run ID"
                                    exit 1
                                fi
                            fi
                            echo "Run ID: \$RUN_ID"
                            
                            # Evaluate model using the run ID
                            docker exec model_trainer sh -c "python -u -m main evaluate_model > /app/model_output.txt 2>&1"
                            
                            # Save model
                            docker exec model_trainer python -m main save_model
                        """

                        // Fetch metrics from MLflow server using the run ID
                        def runId = sh(
                            script: "docker exec model_trainer grep 'MLflow run ID:' /app/train_output.txt | awk '{print \$NF}' || echo ''",
                            returnStdout: true
                        ).trim()
                        
                        if (!runId) {
                            echo "WARNING: Could not find run ID in train_output.txt. Attempting to fetch from MLflow..."
                            runId = sh(
                                script: """
                                    docker exec model_trainer python3 -c '
import mlflow
client = mlflow.MlflowClient("${MLFLOW_TRACKING_URI}")
runs = client.search_runs(experiment_ids=["0"])  # Use search_runs
print(runs[0].info.run_id if runs else "")
'
                                """,
                                returnStdout: true
                            ).trim()
                            if (!runId) {
                                error "Failed to retrieve MLflow run ID from MLflow or train_output.txt"
                            }
                        }
                        echo "Resolved Run ID: ${runId}"

                        def metrics = sh(
                            script: """
                                docker exec model_trainer python3 -c '
import mlflow
from mlflow.tracking import MlflowClient
import json
client = MlflowClient("${MLFLOW_TRACKING_URI}")
run = client.get_run("${runId}")
metrics = run.data.metrics
print(json.dumps(metrics))
'
                            """,
                            returnStdout: true
                        ).trim()

                        def timestamp = sh(script: 'date +%Y%m%d_%H%M%S', returnStdout: true).trim()
                        def metricsMap = new groovy.json.JsonSlurper().parseText(metrics) as Map
                        metricsMap = metricsMap.collectEntries { k, v -> [k, v instanceof groovy.json.internal.LazyMap ? v.toMap() : v] }
                        
                        def labelArgs = metricsMap.collect { k, v ->
                            "-c 'LABEL model.${k}=${v}'"
                        }.join(' ')

                        sh """
                            mkdir -p metrics
                            echo '${metrics}' > metrics/model_metrics.json
                        """

                        withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                                       usernameVariable: 'DOCKER_USERNAME', 
                                       passwordVariable: 'DOCKER_PASSWORD')]) {
                            sh """
                                echo "\$DOCKER_PASSWORD" | docker login -u "\$DOCKER_USERNAME" --password-stdin
                                docker commit \
                                    -c 'LABEL training.timestamp=${timestamp}' \
                                    ${labelArgs} \
                                    model_trainer ${MODEL_IMAGE}:${TAG}
                                docker push ${MODEL_IMAGE}:${TAG}
                                echo "✅ Training complete. Image pushed: ${MODEL_IMAGE}:${TAG}"
                                echo "\\nModel Metrics:"
                                echo '${metrics}' | python3 -m json.tool
                            """
                        }
                        
                        archiveArtifacts artifacts: 'metrics/*.json', fingerprint: true
                        
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error "Model training failed: ${e.message}"
                    }
                }
            }
        }
    }
    
    post {
        always {
            sh '''
                docker rm -f model_trainer || true
                docker rm -f data_container || true
                docker logout
                docker system prune -f
                rm -f model_output.txt train_output.txt
            '''
            cleanWs()
        }
        success {
            echo "Training pipeline completed successfully"
        }
        failure {
            echo "Training pipeline failed"
        }
    }
}
