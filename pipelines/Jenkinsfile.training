// pipelines/Jenkinsfile.training
pipeline {
    agent any
    
    environment {
        BASE_IMAGE = 'hamzachaieb01/ml-pipeline'
        DATA_IMAGE = 'hamzachaieb01/ml-data'
        MODEL_IMAGE = 'hamzachaieb01/ml-model'
        TAG = 'latest'
        MLFLOW_TRACKING_URI = 'http://mlflow:5000'
        WORKSPACE_SAFE = sh(script: 'echo "${WORKSPACE}" | sed "s/ /\\ /g"', returnStdout: true).trim()
    }
    
    options {
        timeout(time: 1, unit: 'HOURS')
        disableConcurrentBuilds()
    }
    
    stages {
        stage('Docker Login') {
            steps {
                withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                               usernameVariable: 'DOCKER_USERNAME', 
                               passwordVariable: 'DOCKER_PASSWORD')]) {
                    sh 'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin'
                }
            }
        }
        
        stage('Pull Images') {
            steps {
                script {
                    sh """
                        docker pull ${BASE_IMAGE}:${TAG}
                        docker pull ${DATA_IMAGE}:${TAG}
                    """
                }
            }
        }
        
        stage('Train Model') {
            steps {
                script {
                    try {
                        // Create data container
                        sh """
                            docker create --name data_container ${DATA_IMAGE}:${TAG}
                        """
                        
                        // Create and start model trainer container
                        sh """
                            # Create container with a sleep command to keep it running
                            docker run -d --name model_trainer \
                                -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \
                                --volumes-from data_container \
                                ${BASE_IMAGE}:${TAG} \
                                tail -f /dev/null
                            
                            # Train model
                            docker exec model_trainer python -m main train_model
                            
                            # Evaluate model
                            docker exec model_trainer python -m main evaluate_model
                            
                            # Save model
                            docker exec model_trainer python -m main save_model
                        """
                        
                        // Get training timestamp
                        def timestamp = sh(script: 'date +%Y%m%d_%H%M%S', returnStdout: true).trim()
                        
                        // Extract all metrics from evaluation output
                        def metrics = sh(
                            script: '''
                                # Try to read metrics from JSON file first
                                METRICS=$(docker exec model_trainer python -c "
                                import json
                                try:
                                    with open('/workspace/model_metrics.json') as f:
                                        metrics = json.load(f)
                                        print(' '.join([f'{k}={v}' for k, v in metrics.items()]))
                                except:
                                    print('')
                                " || echo "")

                                # If JSON not found, try to parse from text file
                                if [ -z "$METRICS" ]; then
                                    METRICS=$(docker exec model_trainer cat /workspace/model_metrics.txt 2>/dev/null | \
                                    grep -oP '(?:Accuracy|Precision|Recall|F1|AUC|MAE|MSE|RMSE): \\K[0-9.]+' | \
                                    awk '{printf("%s=%s ", tolower($1), $2)}' || echo "")
                                fi

                                # If still no metrics, try to parse from logs
                                if [ -z "$METRICS" ]; then
                                    METRICS=$(docker logs model_trainer 2>&1 | \
                                    grep -oP '(?:Model |)(?:Accuracy|Precision|Recall|F1|AUC|MAE|MSE|RMSE): \\K[0-9.]+' | \
                                    awk '{printf("%s=%s ", tolower($1), $2)}')
                                fi

                                echo "$METRICS"
                            ''',
                            returnStdout: true
                        ).trim()
                        
                        // Parse individual metrics
                        def metricsMap = [:]
                        metrics.split().each { metric ->
                            def (key, value) = metric.split('=')
                            metricsMap[key] = value
                        }
                        
                        // Create label arguments for docker commit
                        def labelArgs = metricsMap.collect { k, v -> 
                            "-c 'LABEL model.${k}=${v}'"
                        }.join(' ')
                        
                        // Create and push model images
                        sh """
                            # Commit container to image with all metrics as labels
                            docker commit \
                                -c 'LABEL training.timestamp=${timestamp}' \
                                ${labelArgs} \
                                model_trainer ${MODEL_IMAGE}:${TAG}
                            
                            # Tag with primary metrics
                            docker tag ${MODEL_IMAGE}:${TAG} ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy ?: '0.0'}
                            docker tag ${MODEL_IMAGE}:${TAG} ${MODEL_IMAGE}:${timestamp}
                            
                            # Push all tags
                            docker push ${MODEL_IMAGE}:${TAG}
                            docker push ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy ?: '0.0'}
                            docker push ${MODEL_IMAGE}:${timestamp}
                            
                            echo "âœ… Training complete. Images pushed:"
                            echo "- ${MODEL_IMAGE}:${TAG}"
                            echo "- ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy ?: '0.0'}"
                            echo "- ${MODEL_IMAGE}:${timestamp}"
                            echo "\\nModel Metrics:"
                            echo "${metrics}"
                        """
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error "Model training failed: ${e.message}"
                    }
                }
            }
        }
    }
    
    post {
        always {
            sh '''
                docker rm -f model_trainer || true
                docker rm -f data_container || true
                docker logout
                docker system prune -f
            '''
            cleanWs()
        }
        success {
            echo "Training pipeline completed successfully"
        }
        failure {
            echo "Training pipeline failed"
        }
    }
}
