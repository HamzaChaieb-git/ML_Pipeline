pipeline {
    agent any
    
    environment {
        BASE_IMAGE = 'hamzachaieb01/ml-pipeline'
        DATA_IMAGE = 'hamzachaieb01/ml-data'
        MODEL_IMAGE = 'hamzachaieb01/ml-model'
        TAG = 'latest'
        MLFLOW_TRACKING_URI = 'http://mlflow:5000'
        WORKSPACE_SAFE = sh(script: 'echo "${WORKSPACE}" | sed "s/ /\\ /g"', returnStdout: true).trim()
    }
    
    options {
        timeout(time: 1, unit: 'HOURS')
        disableConcurrentBuilds()
    }
    
    stages {
        stage('Docker Login') {
            steps {
                withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                               usernameVariable: 'DOCKER_USERNAME', 
                               passwordVariable: 'DOCKER_PASSWORD')]) {
                    sh 'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin'
                }
            }
        }
        
        stage('Pull Images') {
            steps {
                script {
                    sh """
                        docker pull ${BASE_IMAGE}:${TAG}
                        docker pull ${DATA_IMAGE}:${TAG}
                    """
                }
            }
        }
        
        stage('Train Model') {
            steps {
                script {
                    try {
                        // Create data container
                        sh """
                            docker create --name data_container ${DATA_IMAGE}:${TAG}
                        """
                        
                        // Create and start model trainer container
                        sh """
                            # Create container with a sleep command to keep it running
                            docker run -d --name model_trainer \
                                -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \
                                --volumes-from data_container \
                                ${BASE_IMAGE}:${TAG} \
                                tail -f /dev/null
                            
                            # Train model
                            docker exec model_trainer python -m main train_model
                            
                            # Evaluate model and save output directly in the container
                            docker exec model_trainer sh -c "python -u -m main evaluate_model > /app/model_output.txt"
                            
                            # Save model
                            docker exec model_trainer python -m main save_model
                        """
                        
                        // Get training timestamp
                        def timestamp = sh(script: 'date +%Y%m%d_%H%M%S', returnStdout: true).trim()
                        
                        // Extract metrics using Python from the container
                        def metrics = sh(
                            script: '''
                                docker exec model_trainer python3 -c "
import re
import json
from sklearn.metrics import classification_report

def parse_metrics(file_path):
    with open(file_path, 'r') as f:
        content = f.read()
    
    metrics = {}
    
    # Get classification report section
    report_match = re.search(r'Classification Report:\\n(.*?)(?:\\n\\n|$)', content, re.DOTALL)
    if report_match:
        report_text = report_match.group(1)
        
        # Extract accuracy
        accuracy_match = re.search(r'accuracy\\s*:\\s*([\\d.]+)', report_text)
        if accuracy_match:
            metrics['accuracy'] = float(accuracy_match.group(1))
        
        # Extract class metrics
        for class_label in ['0', '1']:
            pattern = fr'{class_label}\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)'
            class_match = re.search(pattern, report_text)
            if class_match:
                precision, recall, f1 = map(float, class_match.groups())
                metrics[f'precision_{class_label}'] = precision
                metrics[f'recall_{class_label}'] = recall
                metrics[f'f1_{class_label}'] = f1
        
        # Extract macro/weighted averages
        for avg_type in ['macro avg', 'weighted avg']:
            pattern = fr'{avg_type}\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)'
            avg_match = re.search(pattern, report_text)
            if avg_match:
                precision, recall, f1 = map(float, avg_match.groups())
                prefix = avg_type.replace(' ', '_')
                metrics[f'{prefix}_precision'] = precision
                metrics[f'{prefix}_recall'] = recall
                metrics[f'{prefix}_f1'] = f1
    
    # Get confusion matrix
    matrix_match = re.search(r'Confusion Matrix:\\n(.*?)(?:\\n\\n|$)', content, re.DOTALL)
    if matrix_match:
        matrix_text = matrix_match.group(1)
        # Convert matrix text to numbers and store
        try:
            matrix_lines = [line.strip() for line in matrix_text.split('\\n') if line.strip()]
            matrix = []
            for line in matrix_lines:
                row = [int(x) for x in re.findall(r'\\d+', line)]
                if row:
                    matrix.append(row)
            metrics['confusion_matrix'] = matrix
        except:
            metrics['confusion_matrix'] = None
    
    return metrics

metrics = parse_metrics('/app/model_output.txt')
print(json.dumps(metrics))
"
                            ''',
                            returnStdout: true
                        ).trim()
                        
                        // Parse the JSON metrics manually using Groovy's JsonSlurper
                        def metricsMap = new groovy.json.JsonSlurper().parseText(metrics)
                        
                        // Create label arguments for all metrics
                        def labelArgs = metricsMap.collect { k, v ->
                            if (k == 'confusion_matrix') {
                                return "-c 'LABEL model.${k}=${v.toString().replaceAll('\\s+', '')}'"
                            }
                            return "-c 'LABEL model.${k}=${v}'"
                        }.join(' ')
                        
                        // Save metrics for artifacts
                        sh """
                            mkdir -p metrics
                            cat << EOF > metrics/model_metrics.json
${metrics}
EOF
                        """
                        
                        // Create and push model images with all metrics
                        withCredentials([usernamePassword(credentialsId: 'docker-hub-credentials', 
                                       usernameVariable: 'DOCKER_USERNAME', 
                                       passwordVariable: 'DOCKER_PASSWORD')]) {
                            sh """
                                # Re-login to ensure credentials are fresh
                                echo "\$DOCKER_PASSWORD" | docker login -u "\$DOCKER_USERNAME" --password-stdin
                                
                                # Commit container with all metrics
                                docker commit \
                                    -c 'LABEL training.timestamp=${timestamp}' \
                                    ${labelArgs} \
                                    model_trainer ${MODEL_IMAGE}:${TAG}
                                
                                # Create tags for important metrics
                                docker tag ${MODEL_IMAGE}:${TAG} ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy}
                                docker tag ${MODEL_IMAGE}:${TAG} ${MODEL_IMAGE}:f1_weighted-${metricsMap.weighted_avg_f1}
                                docker tag ${MODEL_IMAGE}:${TAG} ${MODEL_IMAGE}:${timestamp}
                                
                                # Push all tags
                                docker push ${MODEL_IMAGE}:${TAG}
                                docker push ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy}
                                docker push ${MODEL_IMAGE}:f1_weighted-${metricsMap.weighted_avg_f1}
                                docker push ${MODEL_IMAGE}:${timestamp}
                                
                                echo "âœ… Training complete. Images pushed:"
                                echo "- ${MODEL_IMAGE}:${TAG}"
                                echo "- ${MODEL_IMAGE}:accuracy-${metricsMap.accuracy}"
                                echo "- ${MODEL_IMAGE}:f1_weighted-${metricsMap.weighted_avg_f1}"
                                echo "- ${MODEL_IMAGE}:${timestamp}"
                                echo "\\nModel Metrics:"
                                echo '${metrics}' | python3 -m json.tool
                            """
                        }
                        
                        archiveArtifacts artifacts: 'metrics/*.json', fingerprint: true
                        
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error "Model training failed: ${e.message}"
                    }
                }
            }
        }
    }
    
    post {
        always {
            sh '''
                # Remove running containers
                docker rm -f model_trainer || true
                docker rm -f data_container || true
                
                # Keep only latest 2 versions
                REPO="hamzachaieb01/ml-model"
                KEEP_LATEST=2
                
                # Get list of timestamped tags
                TAGS=$(docker images $REPO --format '{{.Tag}}' | grep '^[0-9]' | sort -r)
                
                # Remove old tags
                COUNT=$(echo "$TAGS" | wc -l)
                if [ "$COUNT" -gt "$KEEP_LATEST" ]; then
                    echo "$TAGS" | tail -n +$((KEEP_LATEST + 1)) | while read tag; do
                        docker rmi "$REPO:$tag" || true
                    done
                fi
                
                # Remove any incomplete tags
                docker rmi $(docker images "$REPO" -f "reference=*accuracy-" -q) 2>/dev/null || true
                docker rmi $(docker images "$REPO" -f "reference=*accuracy-0.0" -q) 2>/dev/null || true
                
                # Cleanup
                docker logout
                docker system prune -f
                rm -f model_output.txt
            '''
            cleanWs()
        }
        success {
            echo "Training pipeline completed successfully"
        }
        failure {
            echo "Training pipeline failed"
        }
    }
}
